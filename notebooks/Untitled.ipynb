{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9340ab3b-3134-464f-ab58-f4923307ed84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/14 12:10:01 WARN UDTRegistration: Cannot register UDT for org.geotools.coverage.grid.GridCoverage2D, which is already registered.\n",
      "25/08/14 12:10:01 WARN SimpleFunctionRegistry: The function rs_union_aggr replaced a previously registered function.\n",
      "25/08/14 12:10:01 WARN UDTRegistration: Cannot register UDT for org.locationtech.jts.geom.Geometry, which is already registered.\n",
      "25/08/14 12:10:01 WARN UDTRegistration: Cannot register UDT for org.apache.sedona.common.geometryObjects.Geography, which is already registered.\n",
      "25/08/14 12:10:01 WARN UDTRegistration: Cannot register UDT for org.locationtech.jts.index.SpatialIndex, which is already registered.\n",
      "25/08/14 12:10:01 WARN SimpleFunctionRegistry: The function st_envelope_aggr replaced a previously registered function.\n",
      "25/08/14 12:10:01 WARN SimpleFunctionRegistry: The function st_intersection_aggr replaced a previously registered function.\n",
      "25/08/14 12:10:01 WARN SimpleFunctionRegistry: The function st_union_aggr replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 chips\n",
      "Date range: 2023-01-02 08:25:38.546000 to 2023-01-22 08:25:32.146000\n",
      "Cloud coverage range: 4.0% to 8.9%\n",
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caed3a539cb647bbb513dc7c0fd7592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'sentinel_chips': {'index': [0, 1, 2, 3, 4, 5, 6, 7], 'columns': ['chip_id', 'datetime', 'geohaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from keplergl import KeplerGl\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from sedona.spark import SedonaContext\n",
    "\n",
    "# Create Spark session with Iceberg support\n",
    "spark_conf = SparkConf().setAll([\n",
    "    (\"spark.jars.packages\", \"org.apache.sedona:sedona-spark-3.5_2.12:1.7.2,org.datasyslab:geotools-wrapper:1.7.2-28.5,org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.4.2,org.apache.iceberg:iceberg-aws-bundle:1.4.2\"),\n",
    "    (\"spark.jars.repositories\", \"https://artifacts.unidata.ucar.edu/repository/unidata-all\"),\n",
    "    (\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\"),\n",
    "    (\"spark.sql.catalog.spark_catalog.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\"),\n",
    "    (\"spark.master\", \"local[2]\")\n",
    "])\n",
    "\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"ChipViewer\") \\\n",
    "    .config(conf=spark_conf) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark = SedonaContext.create(spark_session)\n",
    "\n",
    "# Read chip metadata from Iceberg table\n",
    "# Read chips from one geohash area\n",
    "chips_df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        chip_id,\n",
    "        datetime,\n",
    "        geohash,\n",
    "        is_complete,\n",
    "        cloud_coverage,\n",
    "        created_at\n",
    "    FROM sentinel.chips_raw \n",
    "    WHERE geohash = '6wht19'\n",
    "    LIMIT 20\n",
    "\"\"\").toPandas()\n",
    "\n",
    "\n",
    "# Extract chip bounds from chip_id (format: chip_x_y)\n",
    "def get_chip_bounds(chip_id):\n",
    "    parts = chip_id.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        x, y = int(parts[1]), int(parts[2])\n",
    "        # Calculate bounds using chip_size_degrees = 0.023\n",
    "        minx = -180 + (x * 0.023)\n",
    "        miny = -90 + (y * 0.023)\n",
    "        maxx = minx + 0.023\n",
    "        maxy = miny + 0.023\n",
    "        return box(minx, miny, maxx, maxy)\n",
    "    return None\n",
    "\n",
    "# Create GeoDataFrame\n",
    "chips_df['geometry'] = chips_df['chip_id'].apply(get_chip_bounds)\n",
    "chips_gdf = gpd.GeoDataFrame(chips_df.dropna(subset=['geometry']))\n",
    "\n",
    "# Convert datetime to string for Kepler\n",
    "chips_gdf['datetime_str'] = chips_gdf['datetime'].astype(str)\n",
    "chips_gdf['cloud_coverage'] = chips_gdf['cloud_coverage'].fillna(0)\n",
    "\n",
    "print(f\"Loaded {len(chips_gdf)} chips\")\n",
    "print(f\"Date range: {chips_gdf['datetime'].min()} to {chips_gdf['datetime'].max()}\")\n",
    "print(f\"Cloud coverage range: {chips_gdf['cloud_coverage'].min():.1f}% to {chips_gdf['cloud_coverage'].max():.1f}%\")\n",
    "\n",
    "# Create Kepler map\n",
    "map_1 = KeplerGl(height=600)\n",
    "map_1.add_data(data=chips_gdf, name='sentinel_chips')\n",
    "\n",
    "# Display map\n",
    "map_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8e343d-069c-4c1b-aca6-2e86ae14ef4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n",
      "Map saved to chip_viewer.html!\n",
      "\n",
      "Chip locations:\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n",
      "chip_5169_3462: (-61.113, -10.374) to (-61.090, -10.351)\n"
     ]
    }
   ],
   "source": [
    "# Enable Jupyter extension (run this first)\n",
    "import jupyter\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "# Keep only the essential columns for mapping\n",
    "display_cols = ['chip_id', 'geohash', 'is_complete', 'cloud_coverage', 'geometry']\n",
    "chips_display = chips_gdf[display_cols].copy()\n",
    "chips_display['cloud_coverage'] = chips_display['cloud_coverage'].astype(float)\n",
    "\n",
    "map_1 = KeplerGl(height=600)\n",
    "map_1.add_data(data=chips_display, name='sentinel_chips')\n",
    "map_1.save_to_html(file_name='chip_viewer.html')\n",
    "\n",
    "# Also print the data to verify it's working\n",
    "print(\"\\nChip locations:\")\n",
    "for idx, row in chips_gdf.iterrows():\n",
    "    bounds = row.geometry.bounds\n",
    "    print(f\"{row.chip_id}: ({bounds[0]:.3f}, {bounds[1]:.3f}) to ({bounds[2]:.3f}, {bounds[3]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a70f1a-925a-4ad9-b68b-f1546ecaa73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rasterio config: {'GDAL_CACHEMAX': 512, 'CPL_VSIL_CURL_CACHE_SIZE': 200000000, 'GDAL_HTTP_MULTIPLEX': 'YES', 'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR'}\n",
      "\n",
      "=== With Production Rasterio Config ===\n",
      "\n",
      "Testing S2A_20LPN_20230102_0_L2A:\n",
      "  256x256: 0.063s, 0.1MB,  1 chips, 0.0627s/chip\n",
      "  512x512: 0.000s, 0.5MB,  4 chips, 0.0001s/chip\n",
      "  1024x1024: 0.001s, 2.0MB, 16 chips, 0.0001s/chip\n",
      "  1536x1536: 0.414s, 4.5MB, 36 chips, 0.0115s/chip\n",
      "  2048x2048: 0.137s, 8.0MB, 64 chips, 0.0021s/chip\n",
      "  3072x3072: 0.707s, 18.0MB, 144 chips, 0.0049s/chip\n",
      "\n",
      "Testing S2A_20LPP_20230102_0_L2A:\n",
      "  256x256: 0.068s, 0.1MB,  1 chips, 0.0678s/chip\n",
      "  512x512: 0.000s, 0.5MB,  4 chips, 0.0001s/chip\n",
      "  1024x1024: 0.001s, 2.0MB, 16 chips, 0.0000s/chip\n",
      "  1536x1536: 0.204s, 4.5MB, 36 chips, 0.0057s/chip\n",
      "  2048x2048: 0.124s, 8.0MB, 64 chips, 0.0019s/chip\n",
      "  3072x3072: 0.228s, 18.0MB, 144 chips, 0.0016s/chip\n",
      "\n",
      "Testing S2A_20LQP_20230112_0_L2A:\n",
      "  256x256: 0.131s, 0.1MB,  1 chips, 0.1307s/chip\n",
      "  512x512: 0.001s, 0.5MB,  4 chips, 0.0004s/chip\n",
      "  1024x1024: 0.001s, 2.0MB, 16 chips, 0.0000s/chip\n",
      "  1536x1536: 0.579s, 4.5MB, 36 chips, 0.0161s/chip\n",
      "  2048x2048: 0.521s, 8.0MB, 64 chips, 0.0081s/chip\n",
      "  3072x3072: 1.349s, 18.0MB, 144 chips, 0.0094s/chip\n",
      "\n",
      "=== Connection Overhead Test ===\n",
      "10x 256x256 reads:\n",
      "  Multiple connections: 0.085s (0.0085s per read)\n",
      "  Single connection: 0.101s (0.0101s per read)\n",
      "  Connection reuse speedup: 0.8x\n"
     ]
    }
   ],
   "source": [
    "import time, rasterio\n",
    "import numpy as np\n",
    "\n",
    "# Use your rasterio config\n",
    "rasterio_env = {\n",
    "    'GDAL_CACHEMAX': 512,\n",
    "    'CPL_VSIL_CURL_CACHE_SIZE': 200000000,\n",
    "    'GDAL_HTTP_MULTIPLEX': 'YES',\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR'\n",
    "}\n",
    "print(f\"Using rasterio config: {rasterio_env}\")\n",
    "\n",
    "urls = [\n",
    "    's3://sentinel-cogs/sentinel-s2-l2a-cogs/20/L/PN/2023/1/S2A_20LPN_20230102_0_L2A/B02.tif',\n",
    "    's3://sentinel-cogs/sentinel-s2-l2a-cogs/20/L/PP/2023/1/S2A_20LPP_20230102_0_L2A/B02.tif',\n",
    "    's3://sentinel-cogs/sentinel-s2-l2a-cogs/20/L/QP/2023/1/S2A_20LQP_20230112_0_L2A/B02.tif'\n",
    "]\n",
    "\n",
    "sizes = [256, 512, 1024, 1536, 2048, 3072]\n",
    "\n",
    "# Test with your rasterio environment\n",
    "with rasterio.Env(**rasterio_env):\n",
    "    print(\"\\n=== With Production Rasterio Config ===\")\n",
    "    \n",
    "    for url in urls:\n",
    "        scene_name = url.split('/')[-2]\n",
    "        print(f\"\\nTesting {scene_name}:\")\n",
    "        \n",
    "        # Keep connection open for multiple reads (like your UDF does)\n",
    "        with rasterio.open(url) as src:\n",
    "            for size in sizes:\n",
    "                times = []\n",
    "                for i in range(3):\n",
    "                    start = time.time()\n",
    "                    try:\n",
    "                        data = src.read(1, window=((0, size), (0, size)))\n",
    "                        times.append(time.time() - start)\n",
    "                    except Exception as e:\n",
    "                        print(f\"  {size}x{size}: ERROR - {e}\")\n",
    "                        break\n",
    "                \n",
    "                if times:\n",
    "                    avg_time = np.mean(times)\n",
    "                    mb_size = (size * size * 2) / 1024**2\n",
    "                    chips_covered = (size // 256) ** 2\n",
    "                    print(f\"  {size}x{size}: {avg_time:.3f}s, {mb_size:.1f}MB, {chips_covered:2d} chips, {avg_time/chips_covered:.4f}s/chip\")\n",
    "\n",
    "# Also test connection overhead\n",
    "print(\"\\n=== Connection Overhead Test ===\")\n",
    "with rasterio.Env(**rasterio_env):\n",
    "    url = urls[0]\n",
    "    \n",
    "    # Multiple connections (current approach)\n",
    "    start = time.time()\n",
    "    for i in range(10):\n",
    "        with rasterio.open(url) as src:\n",
    "            data = src.read(1, window=((0, 256), (0, 256)))\n",
    "    multi_conn_time = time.time() - start\n",
    "    \n",
    "    # Single connection (optimized approach)\n",
    "    start = time.time()\n",
    "    with rasterio.open(url) as src:\n",
    "        for i in range(10):\n",
    "            data = src.read(1, window=((i*256, (i+1)*256), (0, 256)))\n",
    "    single_conn_time = time.time() - start\n",
    "    \n",
    "    print(f\"10x 256x256 reads:\")\n",
    "    print(f\"  Multiple connections: {multi_conn_time:.3f}s ({multi_conn_time/10:.4f}s per read)\")\n",
    "    print(f\"  Single connection: {single_conn_time:.3f}s ({single_conn_time/10:.4f}s per read)\")\n",
    "    print(f\"  Connection reuse speedup: {multi_conn_time/single_conn_time:.1f}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74deb7b7-b344-479a-bf57-4a499d13a2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tile Size Optimization ===\n",
      "\n",
      "1x1 tiles (256x256, 1 chips):\n",
      "  Avg time: 0.4044s\n",
      "  Per chip: 0.4044s\n",
      "  Data size: 0.1MB\n",
      "  Throughput: 0.3MB/s\n",
      "\n",
      "2x2 tiles (512x512, 4 chips):\n",
      "  Avg time: 0.2784s\n",
      "  Per chip: 0.0696s\n",
      "  Data size: 0.5MB\n",
      "  Throughput: 1.8MB/s\n",
      "\n",
      "3x3 tiles (768x768, 9 chips):\n",
      "  Avg time: 0.2917s\n",
      "  Per chip: 0.0324s\n",
      "  Data size: 1.1MB\n",
      "  Throughput: 3.9MB/s\n",
      "\n",
      "4x4 tiles (1024x1024, 16 chips):\n",
      "  Avg time: 0.2924s\n",
      "  Per chip: 0.0183s\n",
      "  Data size: 2.0MB\n",
      "  Throughput: 6.8MB/s\n",
      "\n",
      "6x6 tiles (1536x1536, 36 chips):\n",
      "  Avg time: 0.4473s\n",
      "  Per chip: 0.0124s\n",
      "  Data size: 4.5MB\n",
      "  Throughput: 10.1MB/s\n",
      "\n",
      "8x8 tiles (2048x2048, 64 chips):\n",
      "  Avg time: 0.8072s\n",
      "  Per chip: 0.0126s\n",
      "  Data size: 8.0MB\n",
      "  Throughput: 9.9MB/s\n",
      "\n",
      "=== Summary ===\n",
      "1x1: 0.4044s/chip, 1.0x speedup, 0.1MB\n",
      "2x2: 0.0696s/chip, 5.8x speedup, 0.5MB\n",
      "3x3: 0.0324s/chip, 12.5x speedup, 1.1MB\n",
      "4x4: 0.0183s/chip, 22.1x speedup, 2.0MB\n",
      "6x6: 0.0124s/chip, 32.5x speedup, 4.5MB\n",
      "8x8: 0.0126s/chip, 32.1x speedup, 8.0MB\n",
      "\n",
      "Optimal tile size: 6x6 (36 chips)\n",
      "\n",
      "=== Memory Analysis ===\n",
      "1x1: 0.6MB per batch\n",
      "2x2: 2.4MB per batch\n",
      "3x3: 5.4MB per batch\n",
      "4x4: 9.6MB per batch\n",
      "6x6: 21.6MB per batch\n",
      "8x8: 38.4MB per batch\n"
     ]
    }
   ],
   "source": [
    "import time, rasterio, math\n",
    "import numpy as np\n",
    "from rasterio.warp import transform_bounds\n",
    "\n",
    "rasterio_env = {\n",
    "    'GDAL_CACHEMAX': 512,\n",
    "    'CPL_VSIL_CURL_CACHE_SIZE': 200000000,\n",
    "    'GDAL_HTTP_MULTIPLEX': 'YES',\n",
    "    'GDAL_DISABLE_READDIR_ON_OPEN': 'EMPTY_DIR'\n",
    "}\n",
    "\n",
    "url = 's3://sentinel-cogs/sentinel-s2-l2a-cogs/20/L/PN/2023/1/S2A_20LPN_20230102_0_L2A/B02.tif'\n",
    "\n",
    "with rasterio.Env(**rasterio_env):\n",
    "    with rasterio.open(url) as src:\n",
    "        # Test multiple tile sizes to find optimal\n",
    "        tile_sizes = [\n",
    "            (1, 256),   # 1x1 = individual chips\n",
    "            (2, 512),   # 2x2 = 4 chips  \n",
    "            (3, 768),   # 3x3 = 9 chips\n",
    "            (4, 1024),  # 4x4 = 16 chips\n",
    "            (6, 1536),  # 6x6 = 36 chips\n",
    "            (8, 2048),  # 8x8 = 64 chips\n",
    "        ]\n",
    "\n",
    "        print(\"=== Tile Size Optimization ===\")\n",
    "        results = {}\n",
    "\n",
    "        for tile_factor, pixel_size in tile_sizes:\n",
    "            chips_per_tile = tile_factor * tile_factor\n",
    "            print(f\"\\n{tile_factor}x{tile_factor} tiles ({pixel_size}x{pixel_size}, {chips_per_tile} chips):\")\n",
    "            \n",
    "            times = []\n",
    "            for test in range(5):  # 5 tests per size\n",
    "                # Random location that fits the tile size\n",
    "                max_x = src.width - pixel_size\n",
    "                max_y = src.height - pixel_size\n",
    "                if max_x <= 0 or max_y <= 0:\n",
    "                    print(f\"  Tile too large for image\")\n",
    "                    break\n",
    "                    \n",
    "                x = np.random.randint(0, max_x)\n",
    "                y = np.random.randint(0, max_y)\n",
    "                \n",
    "                start = time.time()\n",
    "                data = src.read(1, window=((y, y + pixel_size), (x, x + pixel_size)))\n",
    "                times.append(time.time() - start)\n",
    "            \n",
    "            if times:\n",
    "                avg_time = np.mean(times)\n",
    "                per_chip_time = avg_time / chips_per_tile\n",
    "                mb_size = (pixel_size * pixel_size * 2) / 1024**2\n",
    "                \n",
    "                print(f\"  Avg time: {avg_time:.4f}s\")\n",
    "                print(f\"  Per chip: {per_chip_time:.4f}s\") \n",
    "                print(f\"  Data size: {mb_size:.1f}MB\")\n",
    "                print(f\"  Throughput: {mb_size/avg_time:.1f}MB/s\")\n",
    "                \n",
    "                results[tile_factor] = {\n",
    "                    'per_chip_time': per_chip_time,\n",
    "                    'total_time': avg_time,\n",
    "                    'chips_per_tile': chips_per_tile,\n",
    "                    'mb_size': mb_size\n",
    "                }\n",
    "\n",
    "        # Find optimal\n",
    "        if results:\n",
    "            print(f\"\\n=== Summary ===\")\n",
    "            best_tile = min(results.keys(), key=lambda k: results[k]['per_chip_time'])\n",
    "            \n",
    "            for tile_factor in sorted(results.keys()):\n",
    "                r = results[tile_factor]\n",
    "                speedup = results[1]['per_chip_time'] / r['per_chip_time']\n",
    "                print(f\"{tile_factor}x{tile_factor}: {r['per_chip_time']:.4f}s/chip, {speedup:.1f}x speedup, {r['mb_size']:.1f}MB\")\n",
    "            \n",
    "            print(f\"\\nOptimal tile size: {best_tile}x{best_tile} ({results[best_tile]['chips_per_tile']} chips)\")\n",
    "            \n",
    "            # Memory consideration for SageMaker\n",
    "            print(f\"\\n=== Memory Analysis ===\")\n",
    "            for tile_factor in sorted(results.keys()):\n",
    "                r = results[tile_factor]\n",
    "                memory_per_batch = r['chips_per_tile'] * 0.6  # 0.6MB per processed chip\n",
    "                print(f\"{tile_factor}x{tile_factor}: {memory_per_batch:.1f}MB per batch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb033e48-1fb9-4d83-8ee3-c0e99831ca99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fc97ed4921c4a5c93009aaa3130550a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39b163421c0b4a15baf25223f968f15d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6fd66f4f7c514070b07b10185cbafb2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
